{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a try with the former dataset using undersampling\n",
    "from imblearn.under_sampling import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"D:/fast_ai/NLP/cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(path/\"df_1.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer, confusion_matrix, balanced_accuracy_score, accuracy_score,classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2,max_df=0.95,ngram_range=(1,5),stop_words=\"english\")\n",
    "\n",
    "\n",
    "features = vectorizer.fit_transform(df1[\"reviews.text\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5    0.703361\n",
       " 4    0.187142\n",
       " 3    0.043887\n",
       " 1    0.040144\n",
       " 2    0.025466\n",
       " Name: reviews.rating, dtype: float64, 5    0.704756\n",
       " 4    0.182739\n",
       " 3    0.045795\n",
       " 1    0.042492\n",
       " 2    0.024218\n",
       " Name: reviews.rating, dtype: float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train, X_test,y_train,Y_test= train_test_split(features,df1[\"reviews.rating\"],test_size=0.25,random_state=123)\n",
    "y_train.value_counts(normalize=True),Y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3500\n",
       "4    2550\n",
       "3     598\n",
       "1     547\n",
       "2     347\n",
       "Name: reviews.rating, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### slightly undersample training set's dominant target \n",
    "rus = NearMiss(sampling_strategy={5:3500})\n",
    "x_train ,y_train = rus.fit_resample(x_train,y_train)\n",
    "pd.value_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight='balanced',\n",
       "                                     early_stopping=False, epsilon=0.1,\n",
       "                                     eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=-1,\n",
       "                                     penalty='l2', power_t=0.5, random_state=22,\n",
       "                                     shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]),\n",
       "                          'loss': ['hinge', 'log', 'perceptron'],\n",
       "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### make SGD Pipeline\n",
    "clf = SGDClassifier(random_state=22,class_weight=\"balanced\",n_jobs=-1)\n",
    "\n",
    "parameters = [{ 'loss': ['hinge', 'log', 'perceptron'], \n",
    "                'alpha': 10.0**-np.arange(1,7),\n",
    "                'penalty': ['l1', 'l2', 'elasticnet']}]\n",
    "clf_SGD_refined = GridSearchCV(SGDClassifier(random_state=22,n_jobs=-1,class_weight=\"balanced\"), parameters)\n",
    "clf_SGD_refined.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.4913    0.5855    0.5343       193\n",
      "           2     0.1944    0.1273    0.1538       110\n",
      "           3     0.2748    0.1731    0.2124       208\n",
      "           4     0.2585    0.6831    0.3751       830\n",
      "           5     0.8366    0.5008    0.6265      3201\n",
      "\n",
      "    accuracy                         0.5137      4542\n",
      "   macro avg     0.4111    0.4140    0.3804      4542\n",
      "weighted avg     0.6750    0.5137    0.5463      4542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf_SGD_refined.predict(X_test)\n",
    "print(classification_report(Y_test,preds,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
